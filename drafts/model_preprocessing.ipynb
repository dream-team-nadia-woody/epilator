{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import video.df as df\n",
    "from video import vid\n",
    "\n",
    "import video.reader as r\n",
    "import cv2 as cv\n",
    "from video.reader import VideoReader\n",
    "\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from typing import List, Union\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'videos/Red Spin.mp4'\n",
    "vid = vid.Video.from_file(path)\n",
    "vid_df = df.get_vid_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = df.get_exploration_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = df.get_aggregated_df(edf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hazard.01.mp4', 'hazard.02.mp4', 'safe.04.mp4', 'hazard.03.mp4', 'safe.01.mp4', 'hazard.07.mp4', 'hazard.06.mp4', 'data_list.pkl', 'safe.02.mp4', 'hazard.10.mp4', 'hazard.04.mp4', 'hazard.05.mp4', 'safe.03.mp4', 'hidden.05.mp4', 'hazard.08.mp4', 'hazard.09.mp4', 'hidden.04.mp4', 'hidden.06.mp4', 'hidden.03.mp4', 'hidden.02.mp4', 'data.pkl', 'hidden.01.mp4']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# specify the directory path\n",
    "directory_path = \"videos1\"\n",
    "\n",
    "# get the list of filenames in the directory\n",
    "filenames = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "# print the list of filenames\n",
    "print(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid, fps = r.VideoReader.get_vid(path, cv.COLOR_BGR2HLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 126, 255], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750000, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.reshape(-1,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightness_per_frame = vid.reshape(-1, 3)[:, 1].reshape((-1, 50*50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_lightness_per_frame = np.mean(lightness_per_frame,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_lightness_per_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.5124, 32.5144, 31.4948, 32.4748, 33.5124])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_lightness_per_frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame\n",
       "0    33.5124\n",
       "1    32.5144\n",
       "2    31.4948\n",
       "3    32.4748\n",
       "4    33.5124\n",
       "Name: lightness, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.lightness[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifed_lightness = np.concatenate([np.zeros(1), av_lightness_per_frame[:-1]])\n",
    "shifed_lightness[0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame\n",
       "0        NaN\n",
       "1    33.5124\n",
       "2    32.5144\n",
       "3    31.4948\n",
       "4    32.4748\n",
       "Name: lightness, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.lightness.shift(1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    nan, 33.5124, 32.5144, 31.4948, 32.4748])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifed_lightness[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_lightness = shifed_lightness - av_lightness_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-33.5124,   0.998 ,   1.0196,  -0.98  ,  -1.0376])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_lightness[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame\n",
       "0       NaN\n",
       "1    0.9980\n",
       "2    1.0196\n",
       "3   -0.9800\n",
       "4   -1.0376\n",
       "Name: light_diff, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.light_diff[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 50, 50, 3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2500)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightness_per_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lightness_difference(vid: Union[str, ArrayLike], fps: int = 30,\n",
    "               conversion: int = cv.COLOR_BGR2HLS) -> np.array:\n",
    "    '''\n",
    "    returns an numpy array of difference in mean of lightness between frames.\n",
    "    the length of the array = number of video frames - 1\n",
    "    '''\n",
    "    if isinstance(vid, str):\n",
    "        vid, fps = VideoReader.get_vid(vid, conversion)\n",
    "    frames = vid.shape[0]\n",
    "    print(frames)\n",
    "    height = vid.shape[1]\n",
    "    width = vid.shape[2]\n",
    "    # creates an numpy array with the lightness values of each frame\n",
    "    # the shape of the array is (frames, height*width) f.e. (300, 2500)\n",
    "    lightness_per_frame = vid.reshape(-1, 3)[:, 1].reshape((-1, height*width))\n",
    "    # aggregate by mean\n",
    "    av_lightness_per_frame = np.mean(lightness_per_frame,axis=1)\n",
    "    # shift values by 1 position down\n",
    "    shifed_lightness = np.concatenate([np.zeros(1), av_lightness_per_frame[:-1]])\n",
    "    # set 1st value to NaN\n",
    "    shifed_lightness[0] = np.nan\n",
    "    # get the difference in lightness between frames\n",
    "    diff_lightness = shifed_lightness - av_lightness_per_frame\n",
    "    # return all values but NaN\n",
    "    return diff_lightness[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hazard'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('(\\w+)', filenames[0]).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'videos1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in filenames:\n",
    "    if f.endswith('.pkl'):\n",
    "        filenames.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hazard.01.mp4',\n",
       " 'hazard.02.mp4',\n",
       " 'safe.04.mp4',\n",
       " 'hazard.03.mp4',\n",
       " 'safe.01.mp4',\n",
       " 'hazard.07.mp4',\n",
       " 'hazard.06.mp4',\n",
       " 'safe.02.mp4',\n",
       " 'hazard.10.mp4',\n",
       " 'hazard.04.mp4',\n",
       " 'hazard.05.mp4',\n",
       " 'safe.03.mp4',\n",
       " 'hidden.05.mp4',\n",
       " 'hazard.08.mp4',\n",
       " 'hazard.09.mp4',\n",
       " 'hidden.04.mp4',\n",
       " 'hidden.06.mp4',\n",
       " 'hidden.03.mp4',\n",
       " 'hidden.02.mp4',\n",
       " 'hidden.01.mp4']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(directory:str):\n",
    "    '''\n",
    "    returns the list of video files in the directory\n",
    "    '''\n",
    "    # get the list of filenames in the directory\n",
    "    filenames = \\\n",
    "        [f for f in os.listdir(directory) \n",
    "        if (os.path.isfile(os.path.join(directory, f)) and f.endswith('.mp4'))]\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(directory: str):\n",
    "    '''\n",
    "    Goes through every video file in the directory, calculates the lightness difference and\n",
    "    saves it into a dictionary where:\n",
    "    Sequence is the list of light differences for each video\n",
    "    Class name -> hazard / hidden (hazard) / safe\n",
    "    Saves the result into a pickle file in the directory.\n",
    "    If this pickle file exists, loads the data from it.\n",
    "    '''\n",
    "    # create path to the file\n",
    "    pickle_file = 'data.pkl'\n",
    "    pickle_path = directory + '/' + pickle_file\n",
    "    # load the data if file exists and return it\n",
    "    if os.path.isfile(pickle_path):\n",
    "        with open(pickle_path, \"rb\") as fp:\n",
    "            return pickle.load(fp)\n",
    "    else:\n",
    "        # get names of video files\n",
    "        filenames = get_file_names(directory)\n",
    "        # create a dictionary\n",
    "        data = {'Sequence':[], 'ClassName':[]}\n",
    "        for f in filenames:\n",
    "            path = directory + '/' + f\n",
    "            # read the video and get the lightness difference\n",
    "            sq = get_lightness_difference(path)\n",
    "            # get the class name from the file name\n",
    "            class_name = re.search('(\\w+)', f).group()\n",
    "            # append to the lists in data\n",
    "            data['Sequence'].append(sq)\n",
    "            data['ClassName'].append(class_name)\n",
    "        # save data into a pickle file\n",
    "        with open(pickle, \"wb\") as outfile1:\n",
    "            pickle.dump(data, outfile1)\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3927\n",
      "785\n",
      "4561\n",
      "300\n",
      "768\n",
      "7346\n",
      "150\n",
      "2304\n",
      "1521\n",
      "150\n",
      "6314\n",
      "297\n",
      "3933\n",
      "300\n",
      "2375\n",
      "841\n",
      "1159\n",
      "407\n",
      "888\n",
      "1290\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "data = {'Number':[], 'Sequence':[], 'ClassName':[]}\n",
    "for i, file_name in enumerate(filenames):\n",
    "    path = directory + file_name\n",
    "    sq = get_lightness_difference(path)\n",
    "    #print(len(sq))\n",
    "    class_name = re.search('(\\w+)', file_name).group()\n",
    "    data_list.append({'Number': i, 'Sequence': sq, 'ClassName': class_name}) \n",
    "    data['Number'].append(i)\n",
    "    data['Sequence'].append(sq)\n",
    "    data['ClassName'].append(class_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data:dict, pad:str='reflect'):\n",
    "    ''' \n",
    "    for the lightness difference creates a padding.\n",
    "    max length in the train set is 7000+ frames\n",
    "    min is 150. \n",
    "    creates all lists in the data dictionary with length of max length\n",
    "    pad = 'reflect' repeats the values of the sequence\n",
    "    pad = 'constant' will replace the missing values with zeros\n",
    "    '''\n",
    "    # load the values into vectors var\n",
    "    vectors = data['Sequence']\n",
    "\n",
    "    # Determine the maximum length of the vectors\n",
    "    max_len = max(len(v) for v in vectors)\n",
    "\n",
    "    # Pad the vectors\n",
    "    padded_vectors = []\n",
    "    for v in vectors:\n",
    "        padded_vector = np.pad(v, (0, max_len - len(v)), pad)\n",
    "        padded_vectors.append(padded_vector)\n",
    "\n",
    "    # Create a mask\n",
    "    # mask = []\n",
    "    # for v in padded_vectors:\n",
    "    #     mask.append([1] * len(v) + [0] * (max_len - len(v)))\n",
    "\n",
    "    # Convert the lists to numpy arrays\n",
    "    padded_vectors = np.array(padded_vectors)\n",
    "    # mask = np.array(mask)\n",
    "\n",
    "    return padded_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['ClassName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ann(data:dict):\n",
    "    ''' \n",
    "    preprocess the data for ANN\n",
    "    no test set at the moment!!!\n",
    "    need to download more training/test videos\n",
    "\n",
    "    returns X_train and y_train ready to feed to ANN (only)\n",
    "    ''' \n",
    "    X_train = np.array(data['Sequence'])\n",
    "    y_train = np.array(data['ClassName'])\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    # make sure that the label array is of the same data type as the numpy array\n",
    "    le = LabelEncoder()\n",
    "    num_labels = le.fit_transform(y_train)\n",
    "    y_train = num_labels.astype(X_train.dtype)\n",
    "    # create labels on the shape (20, 3) where\n",
    "    # [1., 0., 0.] - 'hazard'\n",
    "    # [0., 0., 1.] - 'safe' \n",
    "    # [0., 1., 0.] - 'hidden hazard'\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_for_labeling = np.array(data['Sequence'])\n",
    "\n",
    "# create a corresponding label array \n",
    "labels = np.array(data['ClassName'])\n",
    "\n",
    "\n",
    "# make sure that the label array is of the same data type as the numpy array\n",
    "le = LabelEncoder()\n",
    "num_labels = le.fit_transform(labels)\n",
    "labels = num_labels.astype(data_for_labeling.dtype)\n",
    "\n",
    "labels = np_utils.to_categorical(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 7345)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_labeling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hazard', 'hazard', 'safe', 'hazard', 'safe', 'hazard', 'hazard',\n",
       "       'safe', 'hazard', 'hazard', 'hazard', 'safe', 'hidden', 'hazard',\n",
       "       'hazard', 'hidden', 'hidden', 'hidden', 'hidden', 'hidden'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 2., 0., 2., 0., 0., 2., 0., 0., 0., 2., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - hazard\n",
    "\n",
    "1 - hidden\n",
    "\n",
    "2 - safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'videos1/safe.04.mp4'\n",
    "vid, fps = VideoReader.get_vid(path, cv.COLOR_BGR2HLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "    frames = vid.shape[0]\n",
    "    height = vid.shape[1]\n",
    "    width = vid.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightness_per_frame = vid.reshape(-1, 3)[:, 1].reshape((-1, height*width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4561, 2500)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightness_per_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifed_lightness = np.concatenate([np.zeros(1), av_lightness_per_frame[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifed_lightness.shape # found an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 11:59:01.192688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "data_for_labeling = sc.fit_transform(data_for_labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=5000, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.7662 - accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 38.1417 - accuracy: 0.8000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 5.9605e-09 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2701f90>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(data_for_labeling, labels,  batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.predict(data_for_labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epilator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
